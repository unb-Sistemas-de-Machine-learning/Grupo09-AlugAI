{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd57852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18b64455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# --- BIBLIOTECAS NECESSÁRIAS PARA SELENIUM ---\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from requests.exceptions import RequestException\n",
    "\n",
    "# ==============================================================================\n",
    "# CONFIGURAÇÕES GLOBAIS\n",
    "# ==============================================================================\n",
    "\n",
    "BASE_URL = \"https://www.dfimoveis.com.br/aluguel/df/todos/apartamento\"\n",
    "\n",
    "# Headers robustos para contornar o 403 (baseado na sua inspeção)\n",
    "USER_AGENT_ROBUSTO = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36'\n",
    "NUM_CLEANER = re.compile(r'[^\\d,\\.]+')\n",
    "\n",
    "# ==============================================================================\n",
    "# FUNÇÕES DE UTILIDADE E REQUISIÇÃO\n",
    "# ==============================================================================\n",
    "\n",
    "def clean_numeric_value(text, is_float=False):\n",
    "    \"\"\"Remove caracteres não numéricos e converte para float/int.\"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "    cleaned = text.replace('R$', '').replace('.', '').replace('m²', '').strip()\n",
    "    cleaned = cleaned.replace(',', '.') \n",
    "    \n",
    "    # Remove tudo que não for dígito ou ponto decimal, mas só se houver dígitos\n",
    "    final_cleaned = re.sub(r'[^\\d\\.]', '', cleaned)\n",
    "    \n",
    "    try:\n",
    "        # Se for inteiro, usamos int(float()) para lidar com strings como '1.0'\n",
    "        if is_float:\n",
    "            return float(final_cleaned)\n",
    "        return int(float(final_cleaned)) \n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "def fetch_html_content_selenium(url):\n",
    "    \"\"\"Usa Selenium para obter o HTML renderizado.\"\"\"\n",
    "    print(f\"\\t-> Buscando URL via Selenium: {url}\")\n",
    "    \n",
    "    chrome_options = Options()\n",
    "    # Modo Headless é crucial para rodar em servidores\n",
    "    chrome_options.add_argument(\"--headless\") \n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_options.add_argument(f\"user-agent={USER_AGENT_ROBUSTO}\") \n",
    "\n",
    "    driver = None\n",
    "    try:\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "        driver.get(url)\n",
    "        time.sleep(5) # Espera para carregar o JS\n",
    "        \n",
    "        html_content = driver.page_source\n",
    "        \n",
    "        if \"captcha\" in driver.current_url.lower() or \"blocked\" in html_content.lower():\n",
    "             raise RequestException(\"Cloudflare CAPTCHA detectado.\")\n",
    "             \n",
    "        return html_content\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\tERRO no acesso via Selenium: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        if driver:\n",
    "            driver.quit()\n",
    "\n",
    "# ==============================================================================\n",
    "# FUNÇÃO DE EXTRAÇÃO DE DETALHES (PÁGINA INDIVIDUAL)\n",
    "# ==============================================================================\n",
    "\n",
    "def extract_detailed_data(html_content, link):\n",
    "    \"\"\"Extrai todas as informações ricas da página de detalhes do imóvel.\"\"\"\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    data = {'link': link}\n",
    "\n",
    "    # --- 1. PREÇO, ÁREA e CUSTOS FIXOS ---\n",
    "    try:\n",
    "        # Preço do aluguel (H4 dentro de div com classe .exibirPrecoSalao)\n",
    "        preco_element = soup.select_one('.exibirPrecoSalao .headline-medium')\n",
    "        data['preco_aluguel_rs'] = clean_numeric_value(preco_element.text, is_float=True) if preco_element else None\n",
    "        \n",
    "        # Área Útil (Valor no H4 próximo ao 'Área Útil:')\n",
    "        area_tag = soup.find('span', string=lambda t: t and 'Área Útil:' in t)\n",
    "        area_element = area_tag.find_next_sibling('h4') if area_tag else None\n",
    "        data['area_m2'] = clean_numeric_value(area_element.text, is_float=True) if area_element else None\n",
    "\n",
    "        # Condomínio\n",
    "        cond_element = soup.select_one('.condom span.label-large.bold')\n",
    "        raw_cond = re.sub(r'[A-Za-z\\r\\n$\\s<>/br]+', '', cond_element.text).replace(',', '.') if cond_element else '0'\n",
    "        data['condominio_rs'] = clean_numeric_value(raw_cond, is_float=True)\n",
    "\n",
    "        # IPTU - CORREÇÃO AQUI\n",
    "        data['iptu_rs'] = 0  # Valor padrão\n",
    "        \n",
    "        # Procura pelo <li> que contém \"IPTU R$:\"\n",
    "        iptu_li = soup.find('li', string=lambda t: t and 'IPTU R$:' in t if t else False)\n",
    "        \n",
    "        if iptu_li:\n",
    "            # Procura pelo <span> com classe grey-color dentro do mesmo <li>\n",
    "            iptu_span = iptu_li.find('span', class_='grey-color')\n",
    "            if iptu_span:\n",
    "                data['iptu_rs'] = clean_numeric_value(iptu_span.text.strip(), is_float=True)\n",
    "        \n",
    "        # Fallback: se não encontrou pelo método acima, tenta buscar por texto direto\n",
    "        if data['iptu_rs'] == 0:\n",
    "            # Busca todos os <li> e verifica se contém \"IPTU\"\n",
    "            all_lis = soup.find_all('li')\n",
    "            for li in all_lis:\n",
    "                li_text = li.get_text()\n",
    "                if 'IPTU R$:' in li_text:\n",
    "                    # Extrai o valor numérico após \"IPTU R$:\"\n",
    "                    iptu_match = re.search(r'IPTU R\\$:\\s*(\\d+(?:,\\d+)?)', li_text)\n",
    "                    if iptu_match:\n",
    "                        data['iptu_rs'] = clean_numeric_value(iptu_match.group(1), is_float=True)\n",
    "                        break\n",
    "\n",
    "        # Valor R$/m²\n",
    "        valor_m2_tag = soup.find('span', string=lambda t: t and 'Valor R$/m²:' in t)\n",
    "        valor_m2_element = valor_m2_tag.find_next_sibling('h4') if valor_m2_tag else None\n",
    "        data['valor_aluguel_m2_rs'] = clean_numeric_value(valor_m2_element.text, is_float=True) if valor_m2_element else None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\t\\t- ERRO na extração de PREÇOS/CUSTOS: {e}\")\n",
    "        data['preco_aluguel_rs'] = None\n",
    "        data['area_m2'] = None\n",
    "        data['condominio_rs'] = 0\n",
    "        data['iptu_rs'] = 0\n",
    "    \n",
    "    # --- 2. CARACTERÍSTICAS E ENDEREÇO ---\n",
    "    try:\n",
    "        # Endereço (SQS 203, ASA SUL, BRASILIA) - Extraído do cabeçalho\n",
    "        local_header = soup.select_one('.imv-map h4.body-medium')\n",
    "        if local_header:\n",
    "            endereco_completo = local_header.text.strip()\n",
    "            # Esperamos: UF - CIDADE - BAIRRO - LOGRADOURO\n",
    "            partes = [p.strip() for p in endereco_completo.split(' - ')]\n",
    "            data['cidade'] = partes[1] if len(partes) > 1 else None\n",
    "            data['bairro'] = partes[2] if len(partes) > 2 else None\n",
    "            data['logradouro'] = partes[3] if len(partes) > 3 else None\n",
    "        \n",
    "        # Quartos/Suítes (o texto contém a contagem)\n",
    "        room_element = soup.select_one('.room span.label-large.bold')\n",
    "        suite_element = soup.select_one('.suite span.label-large.bold')\n",
    "        \n",
    "        data['quartos'] = clean_numeric_value(room_element.text) if room_element else None\n",
    "        data['suites'] = clean_numeric_value(suite_element.text) if suite_element else 0\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\t\\t- ERRO na extração de CARACTERÍSTICAS: {e}\")\n",
    "\n",
    "    # --- 3. GEOLOCALIZAÇÃO ---\n",
    "    try:\n",
    "        lat_script = soup.find('script', string=lambda t: t and 'latitude =' in t)\n",
    "        if lat_script:\n",
    "            lat = re.search(r'latitude = ([-]?[\\d.]+);', lat_script.string).group(1)\n",
    "            lon = re.search(r'longitude = ([-]?[\\d.]+);', lat_script.string).group(1)\n",
    "            data['latitude'] = float(lat)\n",
    "            data['longitude'] = float(lon)\n",
    "        else:\n",
    "            data['latitude'] = None\n",
    "            data['longitude'] = None\n",
    "    except Exception as e:\n",
    "        print(f\"\\t\\t- ERRO na extração de GEOLOCALIZAÇÃO: {e}\")\n",
    "        data['latitude'] = None\n",
    "        data['longitude'] = None\n",
    "\n",
    "    # --- 4. DESCRIÇÃO (Para Features de NLP) ---\n",
    "    descricao_element = soup.select_one('.assined-imv.w-100')\n",
    "    data['descricao_texto'] = descricao_element.text.strip() if descricao_element else ''\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec79156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# FLUXO PRINCIPAL: VALIDAÇÃO DE 1 IMÓVEL\n",
    "# ==============================================================================\n",
    "\n",
    "def run_validation_scrape():\n",
    "    \"\"\"Executa o scraping da página de listagem, pega o primeiro link e raspa os detalhes.\"\"\"\n",
    "    \n",
    "    timestamp = datetime.now()\n",
    "    \n",
    "    # 1. ACESSO À PÁGINA DE LISTAGEM (Para obter links)\n",
    "    html_listagem = fetch_html_content_selenium(BASE_URL)\n",
    "    \n",
    "    if not html_listagem:\n",
    "        print(\"\\nFalha crítica na requisição da página de listagem. Encerrando.\")\n",
    "        return\n",
    "        \n",
    "    soup_listagem = BeautifulSoup(html_listagem, 'html.parser')\n",
    "    \n",
    "    # Encontra o PRIMEIRO card de imóvel\n",
    "    primeiro_card = soup_listagem.find('a', class_='imovel-card')\n",
    "    \n",
    "    if not primeiro_card:\n",
    "        print(\"\\nNenhum imóvel encontrado na primeira página.\")\n",
    "        return\n",
    "    \n",
    "    # Extrai o link do primeiro imóvel\n",
    "    link_primeiro_imovel = primeiro_card.get('href', 'N/A')\n",
    "    if not link_primeiro_imovel.startswith('http'):\n",
    "        link_primeiro_imovel = \"https://www.dfimoveis.com.br\" + link_primeiro_imovel\n",
    "        \n",
    "    print(f\"\\n[Validação] Link do Primeiro Imóvel: {link_primeiro_imovel}\")\n",
    "    \n",
    "    # 2. ACESSO À PÁGINA DE DETALHE (O passo mais importante)\n",
    "    html_detalhe = fetch_html_content_selenium(link_primeiro_imovel)\n",
    "    \n",
    "    if not html_detalhe:\n",
    "        print(\"\\nFalha na requisição da página de detalhe. Encerrando.\")\n",
    "        return\n",
    "\n",
    "    # 3. EXTRAÇÃO DOS DADOS RICOS\n",
    "    dados_detalhados = extract_detailed_data(html_detalhe, link_primeiro_imovel)\n",
    "\n",
    "    # 4. IMPRESSÃO PARA VALIDAÇÃO\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"           RESULTADOS DA EXTRAÇÃO DETALHADA\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for key, value in dados_detalhados.items():\n",
    "        if key == 'descricao_texto':\n",
    "            print(f\"{key}: {value[:100]}...\") # Imprime só os primeiros 100 caracteres\n",
    "        else:\n",
    "            print(f\"{key}: {value}\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # 5. RETORNA UM DATAFRAME DE 1 LINHA\n",
    "    df = pd.DataFrame([dados_detalhados])\n",
    "    print(\"\\n--- DataFrame Gerado para Validação ---\")\n",
    "    print(df[['cidade', 'bairro', 'logradouro', 'preco_aluguel_rs', 'condominio_rs', 'iptu_rs', 'valor_aluguel_m2_rs', 'area_m2', 'quartos', 'suites', 'latitude']].T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cb039b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t-> Buscando URL via Selenium: https://www.dfimoveis.com.br/aluguel/df/todos/apartamento\n",
      "\n",
      "[Validação] Link do Primeiro Imóvel: https://www.dfimoveis.com.br/imovel/apartamento-2-quartos-aluguel-asa-sul-brasilia-df-sqs-203-1240085\n",
      "\t-> Buscando URL via Selenium: https://www.dfimoveis.com.br/imovel/apartamento-2-quartos-aluguel-asa-sul-brasilia-df-sqs-203-1240085\n",
      "\n",
      "==================================================\n",
      "           RESULTADOS DA EXTRAÇÃO DETALHADA\n",
      "==================================================\n",
      "link: https://www.dfimoveis.com.br/imovel/apartamento-2-quartos-aluguel-asa-sul-brasilia-df-sqs-203-1240085\n",
      "preco_aluguel_rs: 8200.0\n",
      "area_m2: 119.0\n",
      "condominio_rs: 1513.0\n",
      "iptu_rs: 238.0\n",
      "valor_aluguel_m2_rs: 68.0\n",
      "cidade: BRASILIA\n",
      "bairro: ASA SUL\n",
      "logradouro: SQS 203\n",
      "quartos: 2\n",
      "suites: 2\n",
      "latitude: -15.808588\n",
      "longitude: -47.8887643\n",
      "descricao_texto: Este lindo apartamento une sofisticação e funcionalidade em uma das localizações mais desejadas de B...\n",
      "==================================================\n",
      "\n",
      "\n",
      "--- DataFrame Gerado para Validação ---\n",
      "                             0\n",
      "cidade                BRASILIA\n",
      "bairro                 ASA SUL\n",
      "logradouro             SQS 203\n",
      "preco_aluguel_rs        8200.0\n",
      "condominio_rs           1513.0\n",
      "iptu_rs                  238.0\n",
      "valor_aluguel_m2_rs       68.0\n",
      "area_m2                  119.0\n",
      "quartos                      2\n",
      "suites                       2\n",
      "latitude            -15.808588\n"
     ]
    }
   ],
   "source": [
    "# Teste rápido\n",
    "if __name__ == '__main__':\n",
    "    run_validation_scrape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5f2950",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
